image: mcr.microsoft.com/dotnet/sdk:8.0

stages:
  - build
  - test
  - report
  - monitor
  - deploy

build-job:
  stage: build
  script:
    - echo "Compiling the code..."
    - echo "Compile complete."

dotnet-test:
  stage: test
  services:
    - name: selenium/standalone-chrome:latest
      alias: selenium-standalone
  script:
    - dotnet restore
    - dotnet test StepikTesting.sln --logger "trx" --results-directory TestResults
  artifacts:
    when: always
    reports:
      junit:
        - TestResults/*.trx
    paths:
      - TestResults/
    expire_in: 1 week
  allow_failure: true

allure-report:
  image: openjdk:11-jdk
  stage: report
  before_script:
    - apt-get update && apt-get install -y wget unzip
    - wget https://github.com/allure-framework/allure2/releases/download/2.21.0/allure-2.21.0.zip
    - unzip allure-2.21.0.zip -d /opt/
    - ln -s /opt/allure-2.21.0/bin/allure /usr/local/bin/allure
  script:
    - allure generate TestResults --clean -o allure-report
    - |
      # Create Allure properties to configure screenshot display
      mkdir -p allure-report/data
      cat > allure-report/data/environment.json << EOF
      {
        "allure": {
          "directory": "allure-results",
          "links": [],
          "environment": {
            "runtime": "net8.0",
            "allure_version": "2.21.0",
            "specflow_version": "3.9.74"
          }
        }
      }
      EOF
  artifacts:
    paths:
      - allure-report/
    expire_in: 1 week
  dependencies:
    - dotnet-test
    
grafana-monitor:
  stage: monitor
  image: grafana/grafana:latest
  variables:
    GF_SECURITY_ADMIN_PASSWORD: "admin"
    GF_INSTALL_PLUGINS: "grafana-piechart-panel,grafana-clock-panel,mtanda-histogram-panel"
    GF_PATHS_DATA: "/var/lib/grafana"
    GF_PATHS_LOGS: "/var/log/grafana"
    GF_PATHS_PLUGINS: "/var/lib/grafana/plugins"
  before_script:
    - apk add --no-cache curl jq
    - mkdir -p /etc/grafana/provisioning/dashboards /etc/grafana/provisioning/datasources
    - mkdir -p /var/lib/grafana/dashboards
    - chown -R 472:472 /var/lib/grafana
  script:
    - |
      # Create datasource configuration for Prometheus (assuming Prometheus is available)
      cat > /etc/grafana/provisioning/datasources/datasource.yml << EOF
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://prometheus:9090
          isDefault: true
      EOF
    - |
      # Create dashboard configuration
      cat > /etc/grafana/provisioning/dashboards/dashboard.yml << EOF
      apiVersion: 1
      providers:
        - name: 'Test Metrics'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          updateIntervalSeconds: 10
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards
      EOF
    - |
      # Generate test metrics dashboard from test results
      cat > /var/lib/grafana/dashboards/test-metrics.json << EOF
      {
        "dashboard": {
          "id": null,
          "title": "Test Execution Metrics",
          "tags": ["tests", "ci"],
          "timezone": "browser",
          "panels": [
            {
              "id": 1,
              "title": "Test Results Summary",
              "type": "stat",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
              "targets": [
                {
                  "expr": "test_total_tests",
                  "legendFormat": "Total Tests"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "color": {"mode": "palette-classic"},
                  "unit": "short"
                }
              }
            },
            {
              "id": 2,
              "title": "Test Success Rate",
              "type": "gauge",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
              "targets": [
                {
                  "expr": "test_success_rate",
                  "legendFormat": "Success Rate"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "min": 0,
                  "max": 100,
                  "unit": "percent"
                }
              }
            },
            {
              "id": 3,
              "title": "Test Execution Time Trend",
              "type": "graph",
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
              "targets": [
                {
                  "expr": "test_execution_time",
                  "legendFormat": "Execution Time"
                }
              ]
            }
          ],
          "time": {"from": "now-1h", "to": "now"},
          "refresh": "10s"
        },
        "folderId": 0,
        "overwrite": true
      }
      EOF
    - |
      # Start Grafana in background
      /run.sh &
      GRAFANA_PID=$!
      
      # Wait for Grafana to start
      echo "Waiting for Grafana to start..."
      max_attempts=30
      attempt=1
      until curl -s http://localhost:3000/api/health > /dev/null; do
        if [ $attempt -eq $max_attempts ]; then
          echo "Grafana failed to start within the expected time"
          exit 1
        fi
        echo "Attempt $attempt/$max_attempts: Grafana not ready yet..."
        sleep 2
        attempt=$((attempt + 1))
      done
      
      echo "Grafana is running and ready!"
      echo "Grafana Dashboard URL: http://localhost:3000"
      echo "Username: admin"
      echo "Password: admin"
      
      # Import test results data and create dashboard via API
      echo "Setting up test metrics dashboard..."
      
      # Create dashboard via API
      DASHBOARD_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" \
        -X POST \
        -H "Content-Type: application/json" \
        -H "Accept: application/json" \
        -d '{
          "dashboard": {
            "title": "CI Test Analytics - Pipeline $CI_PIPELINE_ID",
            "tags": ["ci", "tests", "pipeline-$CI_PIPELINE_ID"],
            "timezone": "browser",
            "panels": [
              {
                "id": 1,
                "title": "Pipeline Information",
                "type": "text",
                "gridPos": {"h": 3, "w": 24, "x": 0, "y": 0},
                "mode": "markdown",
                "content": "# Pipeline $CI_PIPELINE_ID\\n**Branch:** $CI_COMMIT_REF_NAME\\n**Commit:** $CI_COMMIT_SHORT_SHA\\n**Triggered by:** $GITLAB_USER_NAME"
              }
            ],
            "time": {"from": "now-1h", "to": "now"}
          },
          "folderId": 0,
          "overwrite": true
        }' \
        http://admin:admin@localhost:3000/api/dashboards/db)
      
      if [ "$DASHBOARD_RESPONSE" = "200" ]; then
        echo "Dashboard created successfully!"
      else
        echo "Dashboard creation response: $DASHBOARD_RESPONSE"
      fi
      
      # Display access information
      echo "=== Grafana Monitoring ==="
      echo "Access your Grafana instance at: http://localhost:3000"
      echo "Credentials: admin / admin"
      echo "The service will remain active for 10 minutes for manual inspection"
      echo "Press Ctrl+C to stop earlier"
      echo "=========================="
      
      # Keep Grafana running for manual inspection (10 minutes)
      sleep 600
      
      # Clean shutdown
      echo "Stopping Grafana..."
      kill $GRAFANA_PID
      wait $GRAFANA_PID
      echo "Grafana monitoring session completed"
  artifacts:
    paths:
      - /var/lib/grafana/dashboards/
    reports:
      junit:
        - TestResults/*.trx
    expire_in: 1 week
  dependencies:
    - dotnet-test
  allow_failure: true
  when: manual
  tags:
    - docker
  

deploy-job:
  stage: deploy
  environment: production
  script:
    - echo "Deploying application..."
    - echo "Application successfully deployed."